# 10. 데이터 처리 및 시각화

## `NumPy` 배열 연산

`NumPy`는 Python을 위한 고성능 과학 계산 라이브러리이며, `ndarray`라는 다차원 배열 객체를 중심으로 다양한 수치 연산 기능을 제공한다.
 배열 간 연산은 벡터화(vectorization)되어 있으며, **for 루프 없이도 대규모 데이터를 효율적으로 처리할 수 있다.**

### 1. 배열 생성

```
import numpy as np

a = np.array([1, 2, 3])
b = np.array([4, 5, 6])
```

### 2. 기본 산술 연산

NumPy는 **동일한 shape을 가진 배열 간** 연산을 지원하며, **스칼라값에 대해서도 브로드캐스팅**이 자동으로 수행된다.

```
a + b         # array([5, 7, 9])
a - b         # array([-3, -3, -3])
a * b         # array([ 4, 10, 18])
a / b         # array([0.25, 0.4 , 0.5 ])
a ** 2        # 제곱 연산: array([1, 4, 9])
a + 10        # 스칼라 브로드캐스팅: array([11, 12, 13])
```

### 3. 브로드캐스팅 (Broadcasting)

차원이 다른 배열 간에도 **자동으로 shape을 맞춰 연산**이 가능하다.

```
a = np.array([[1], [2], [3]])       # shape: (3, 1)
b = np.array([10, 20, 30])          # shape: (3,)
a + b
# → shape (3, 3) 결과 반환
```

브로드캐스팅 규칙은 오른쪽에서부터 shape을 비교하며, 둘 중 하나가 `1`이거나 일치하면 확장 가능하다.

### 4. 유니버설 함수 (ufunc)

`numpy`는 고속 계산을 위한 다양한 유니버설 함수(단일 배열 원소별 처리 함수)를 제공한다.

```
np.sqrt(a)     # 제곱근
np.exp(a)      # 자연지수
np.log(a)      # 자연로그
np.sin(a)      # 사인 함수
np.abs(a)      # 절댓값
```

이러한 함수는 내부적으로 **C로 구현된 고속 루프를 사용하며**, 배열 전체를 벡터화하여 매우 빠르게 계산된다.

### 5. 비교 연산 및 논리 연산

```
a = np.array([1, 2, 3])
b = np.array([2, 2, 2])

a > b          # array([False, False, True])
a == 2         # array([False, True, False])
np.logical_and(a > 0, a < 3)  # array([ True,  True, False])
```

### 6. 집계 함수 (Aggregation)

```
a = np.array([[1, 2], [3, 4]])

a.sum()             # 전체 합계: 10
a.mean()            # 평균값: 2.5
a.max(), a.min()    # 최대, 최소
a.std(), a.var()    # 표준편차, 분산
a.sum(axis=0)       # 열 기준 합: array([4, 6])
a.sum(axis=1)       # 행 기준 합: array([3, 7])
```

### 7. 행렬 곱

- 원소 곱(`*`)과 행렬 곱(`@`)은 다르다.

```
A = np.array([[1, 2], [3, 4]])
B = np.array([[2, 0], [1, 2]])

A * B         # 원소별 곱
A @ B         # 행렬 곱
np.dot(A, B)  # 동일한 행렬 곱
```

### 8. 배열 인덱싱 및 조건 선택

```
a = np.array([10, 20, 30, 40, 50])

a[1:4]          # 슬라이싱: [20 30 40]
a[a > 30]       # 조건 필터링: [40 50]
np.where(a > 30, 1, 0)  # 조건 만족 → 1, 불만족 → 0
```

### 9. 타입 변환

```
a = np.array([1.5, 2.5, 3.5])
a.astype(int)    # array([1, 2, 3])
```

### 10. 벡터화된 반복 처리

Python의 루프보다 훨씬 빠른 **벡터 연산 처리**가 가능하다.

```
x = np.arange(1e6)
%timeit x * 2
# 매우 빠른 실행 시간
```

### 📌 정리: 주요 연산 요약

| 연산 유형     | 함수 또는 연산자                       |
| ------------- | -------------------------------------- |
| 산술 연산     | `+`, `-`, `*`, `/`, `**`               |
| 브로드캐스팅  | 자동 적용                              |
| 유니버설 함수 | `np.sqrt()`, `np.sin()`, `np.exp()` 등 |
| 비교/논리     | `==`, `>`, `logical_and`, `where` 등   |
| 집계          | `sum()`, `mean()`, `max()`, `std()` 등 |
| 행렬 곱       | `@`, `np.dot()`                        |
| 인덱싱        | 슬라이싱, 불리언 인덱스                |

NumPy의 배열 연산은 **단일 값 기반의 반복 처리보다 수십~수백 배 이상 빠르며**,
 **딥러닝, 통계분석, 물리 시뮬레이션 등 수치 중심 작업의 기반 기술**로 널리 사용된다.

## `Pandas`를 이용한 데이터프레임 처리

`pandas`는 Python의 대표적인 **데이터 분석/조작 라이브러리**로, 표 형태의 데이터를 다루는 **DataFrame 객체**를 중심으로 다양한 기능을 제공한다.
 이는 엑셀, SQL, CSV, 시계열, 통계 분석 등 다양한 데이터 소스를 통합하여 처리할 수 있게 해준다.

### 1. 모듈 임포트

```
import pandas as pd
```

### 2. 데이터프레임 생성

#### 2.1 딕셔너리 기반 생성

```
data = {
    "name": ["Alice", "Bob", "Charlie"],
    "age": [25, 30, 35],
    "score": [85.5, 92.0, 78.0]
}

df = pd.DataFrame(data)
```

#### 2.2 CSV 파일로부터 생성

```
df = pd.read_csv("data.csv")
```

#### 2.3 Excel 파일

```
df = pd.read_excel("data.xlsx")
```

### 3. 데이터프레임 구조 확인

```
df.shape          # (행 수, 열 수)
df.columns        # 열 이름
df.index          # 인덱스 정보
df.info()         # 데이터 요약
df.describe()     # 수치형 통계 요약
df.head(5)        # 상위 5개 행
df.tail(5)        # 하위 5개 행
```

### 4. 열(Column) 및 행(Row) 선택

```
df["name"]            # 단일 열 선택
df[["name", "score"]] # 여러 열 선택

df.loc[0]             # 라벨 기반 행 선택
df.iloc[1]            # 위치 기반 행 선택

df.loc[0, "name"]     # 특정 셀
```

### 5. 조건 필터링

```
df[df["age"] > 28]                        # 조건 필터링
df[(df["age"] > 28) & (df["score"] < 90)] # 복합 조건
```

### 6. 새로운 열 추가 및 수정

```
df["passed"] = df["score"] >= 80
```

### 7. 결측값 처리 (NaN)

```
df.isnull()             # 결측값 여부
df.dropna()             # 결측값 포함 행 제거
df.fillna(0)            # 결측값 채우기
df["score"].fillna(df["score"].mean(), inplace=True)
```

### 8. 정렬 및 정렬 조건

```
df.sort_values("age", ascending=True)
df.sort_values(["age", "score"], ascending=[True, False])
```

### 9. 그룹 연산 (`groupby`)

```
df.groupby("passed")["score"].mean()
df.groupby("name").agg({"score": "mean", "age": "max"})
```

### 10. 집계 함수

```
df["score"].sum()
df["score"].mean()
df["score"].max()
df["score"].value_counts()
```

### 11. 데이터프레임 병합 및 연결

#### 11.1 수직 연결 (`concat`)

```
pd.concat([df1, df2], axis=0)
```

#### 11.2 수평 병합 (`merge`)

```
pd.merge(df1, df2, on="id", how="inner")
```

### 12. 데이터 저장

```
df.to_csv("output.csv", index=False)
df.to_excel("output.xlsx", index=False)
```

### 13. 날짜 및 시계열 처리

```
df["date"] = pd.to_datetime(df["date"])
df.set_index("date", inplace=True)
df.resample("M").mean()  # 월별 평균
```

### 14. 기타 유용한 함수

| 함수                                       | 설명                  |
| ------------------------------------------ | --------------------- |
| `df.rename()`                              | 열 이름 변경          |
| `df.drop()`                                | 열 또는 행 제거       |
| `df.apply()`                               | 사용자 정의 함수 적용 |
| `df.map()` / `df.replace()`                | 값 매핑 및 치환       |
| `df.duplicated()` / `df.drop_duplicates()` | 중복 행 탐지 및 제거  |
| `df.memory_usage()`                        | 메모리 사용량 확인    |

### 📌 요약

| 작업   | 함수/방법                        |
| ------ | -------------------------------- |
| 생성   | `pd.DataFrame()`, `read_csv()`   |
| 조회   | `head()`, `info()`, `describe()` |
| 선택   | `[]`, `.loc[]`, `.iloc[]`        |
| 필터링 | 조건식                           |
| 집계   | `sum()`, `mean()`, `groupby()`   |
| 정렬   | `sort_values()`                  |
| 결측값 | `dropna()`, `fillna()`           |
| 병합   | `concat()`, `merge()`            |
| 저장   | `to_csv()`, `to_excel()`         |

`pandas`는 **구조화된 데이터를 정제, 분석, 시각화, 저장하는 데 있어 Python 생태계의 핵심 도구**이다.

## `Matplotlib`, `Seaborn`을 활용한 시각화

### 1. 모듈 임포트

```
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
python코드 복사# 시각화 스타일 지정 (옵션)
sns.set(style="whitegrid")  # 배경 그리드 적용
plt.rcParams["font.size"] = 12  # 글꼴 크기 조정
```

### 2. 기초 시각화 (`Matplotlib` 중심)

#### 2.1 선 그래프 (Line plot)

```
x = np.linspace(0, 10, 100)
y = np.sin(x)

plt.plot(x, y, label="sin(x)")
plt.title("Sine Curve")
plt.xlabel("x-axis")
plt.ylabel("y-axis")
plt.legend()
plt.grid(True)
plt.show()
```

#### 2.2 막대 그래프 (Bar plot)

```
categories = ["A", "B", "C"]
values = [10, 20, 15]

plt.bar(categories, values, color="skyblue")
plt.title("Category Counts")
plt.show()
```

#### 2.3 산점도 (Scatter plot)

```
x = np.random.rand(50)
y = np.random.rand(50)

plt.scatter(x, y, c="green", alpha=0.7)
plt.title("Random Scatter")
plt.show()
```

### 3. Seaborn 기본 그래프

#### 3.1 히스토그램 및 밀도그래프

```
data = np.random.normal(loc=0, scale=1, size=1000)

sns.histplot(data, bins=30, kde=True, color="purple")
plt.title("Histogram with KDE")
plt.show()
```

#### 3.2 박스 플롯 (Box plot)

```
tips = sns.load_dataset("tips")
sns.boxplot(x="day", y="total_bill", data=tips)
plt.title("Total Bill by Day")
plt.show()
```

#### 3.3 바이올린 플롯 (Violin plot)

```
sns.violinplot(x="day", y="tip", data=tips, inner="quartile")
plt.title("Tip Distribution by Day")
plt.show()
```

### 4. 관계 시각화 (다변량 분석)

#### 4.1 산점도 + 회귀선 (regplot)

```
sns.regplot(x="total_bill", y="tip", data=tips)
plt.title("Tip vs Total Bill")
plt.show()
```

#### 4.2 `pairplot`: 변수 간 관계 행렬

```
sns.pairplot(tips, hue="sex")
plt.suptitle("Pairwise Plots", y=1.02)
plt.show()
```

#### 4.3 `heatmap`: 상관 계수 시각화

```
corr = tips.corr()
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()
```

### 5. 그래프 저장

```
plt.savefig("figure.png", dpi=300, bbox_inches="tight")
```

### 6. 주요 비교

| 항목         | Matplotlib         | Seaborn                             |
| ------------ | ------------------ | ----------------------------------- |
| 목적         | 저수준 시각화 도구 | 고수준 통계 시각화                  |
| 스타일       | 수동 구성          | 자동 스타일 적용                    |
| 커스터마이징 | 매우 유연          | 기본은 간단, 확장은 Matplotlib 이용 |
| 통계 지원    | ❌ 없음             | ✅ 평균선, 회귀선, KDE 등 포함       |
| 의존성       | 표준               | `Matplotlib`에 의존                 |

### 📌 요약

| 기능        | Matplotlib      | Seaborn             |
| ----------- | --------------- | ------------------- |
| 선 그래프   | `plt.plot()`    | `sns.lineplot()`    |
| 막대 그래프 | `plt.bar()`     | `sns.barplot()`     |
| 산점도      | `plt.scatter()` | `sns.scatterplot()` |
| 히스토그램  | `plt.hist()`    | `sns.histplot()`    |
| 상자그림    | `boxplot()`     | `sns.boxplot()`     |
| 회귀선      | 없음            | `sns.regplot()`     |
| 관계 행렬   | ❌               | `sns.pairplot()`    |
| 상관 행렬   | ❌               | `sns.heatmap()`     |

둘 중 하나만 사용하는 경우도 많지만, 일반적으로는:

- **탐색적 분석 (EDA)** → `Seaborn`
- **고급 사용자 정의 시각화** → `Matplotlib`

을 함께 사용하는 방식이 가장 실용적이다.

## 파일 포맷 입출력

Python은 기본 내장 함수 및 `pandas`, `json`, `pickle`, `csv`, `openpyxl` 등의 외부 라이브러리를 통해 다양한 파일 포맷을 읽고 쓸 수 있다.

### 1. 📄 텍스트 파일 (`.txt`)

#### 읽기

```
with open("file.txt", "r", encoding="utf-8") as f:
    contents = f.read()
```

#### 쓰기

```
with open("file.txt", "w", encoding="utf-8") as f:
    f.write("내용을 씁니다.")
```

### 2. 📋 CSV 파일

#### pandas로 읽기

```
import pandas as pd

df = pd.read_csv("data.csv")
```

#### pandas로 쓰기

```
df.to_csv("output.csv", index=False, encoding="utf-8")
```

#### csv 모듈 사용 (표준 라이브러리)

```
import csv

with open("data.csv", newline="") as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)
```

### 3. 📊 Excel 파일 (`.xlsx`, `.xls`)

#### 읽기

```
df = pd.read_excel("data.xlsx")
```

#### 쓰기

```
df.to_excel("output.xlsx", index=False)
```

> Excel 입출력은 `openpyxl`, `xlsxwriter`, `xlrd` 등의 백엔드 라이브러리 설치가 필요할 수 있음

```
pip install openpyxl
```

### 4. 📦 JSON 파일

#### 읽기

```
import json

with open("data.json", "r", encoding="utf-8") as f:
    data = json.load(f)
```

#### 쓰기

```
with open("output.json", "w", encoding="utf-8") as f:
    json.dump(data, f, indent=2, ensure_ascii=False)
```

### 5. 🧬 Pickle 파일 (Python 객체 직렬화)

#### 저장 (쓰기)

```
import pickle

with open("model.pkl", "wb") as f:
    pickle.dump(my_object, f)
```

#### 불러오기 (읽기)

```
with open("model.pkl", "rb") as f:
    obj = pickle.load(f)
```

> 주의: Pickle은 **보안상 신뢰할 수 없는 파일에 사용 금지**

### 6. 🧾 Parquet (대용량 컬럼형 저장)

```
df.to_parquet("data.parquet", engine="pyarrow")
df = pd.read_parquet("data.parquet")
```

```
pip install pyarrow
```

### 7. 🧷 압축 파일 다루기

#### ZIP 파일 읽기/쓰기

```
import zipfile

with zipfile.ZipFile("archive.zip", "r") as zipf:
    zipf.extractall("output_dir")

with zipfile.ZipFile("archive.zip", "w") as zipf:
    zipf.write("file.txt")
```

### 8. 📁 디렉토리 내 파일 일괄 처리

```
import os

for filename in os.listdir("data"):
    if filename.endswith(".csv"):
        df = pd.read_csv(os.path.join("data", filename))
        # 파일별 처리
```

### 📌 파일 입출력 요약 표

| 포맷    | 읽기                             | 쓰기                           |
| ------- | -------------------------------- | ------------------------------ |
| 텍스트  | `open(...).read()`               | `open(...).write()`            |
| CSV     | `pd.read_csv()` / `csv.reader()` | `df.to_csv()` / `csv.writer()` |
| Excel   | `pd.read_excel()`                | `df.to_excel()`                |
| JSON    | `json.load()`                    | `json.dump()`                  |
| Pickle  | `pickle.load()`                  | `pickle.dump()`                |
| Parquet | `pd.read_parquet()`              | `df.to_parquet()`              |

### ✅ 실전 팁

- 텍스트 인코딩은 항상 `encoding="utf-8"` 또는 `encoding="cp949"` 등을 명시할 것
- Pandas의 `read_*()` 계열 함수는 **결측값 처리, 인덱스 지정, 열 이름 지정** 등 다양한 인자를 지원
- 파일 존재 여부 확인: `os.path.exists()`
- 파일 확장자 판별: `os.path.splitext(filename)`

## 고급 데이터 처리

### 1️⃣ 그룹 연산 (`groupby`)

```
df.groupby("key")["value"].mean()
df.groupby(["col1", "col2"]).agg({"sales": "sum", "price": "mean"})
```

- 그룹 단위로 평균, 합계, 카운트 등 적용
- `agg()`로 여러 연산을 컬럼별로 지정 가능

### 2️⃣ 사용자 정의 함수 적용 (`apply`)

```
def categorize(score):
    if score >= 90:
        return "A"
    elif score >= 80:
        return "B"
    return "C"

df["grade"] = df["score"].apply(categorize)
```

- 모든 행/열에 대해 함수 적용 가능
- **행 단위**: `df.apply(func, axis=1)`
- **열 단위**: 기본 axis=0

### 3️⃣ 피벗 및 재구조화

#### 3.1 `pivot_table`

```
df.pivot_table(index="region", columns="year", values="sales", aggfunc="sum")
```

- 범주형 데이터를 열로 펼침
- `aggfunc`: `"mean"`, `"sum"`, `"count"` 등

#### 3.2 `melt` – Wide → Long 변환

```
pd.melt(df, id_vars=["name"], var_name="subject", value_name="score")
```

### 4️⃣ 다중 인덱스 처리 (MultiIndex)

```
df = df.set_index(["region", "year"])
df.loc[("Seoul", 2023)]
df.reset_index()  # 인덱스 복구
```

- 계층 구조를 가진 인덱스를 통해 그룹화 또는 피벗 가능

### 5️⃣ 조건부 집계와 `query()`

```
df.query("score >= 80 and age < 30")
```

- 문자열로 조건 표현 (SQL-like)
- `.eval()`도 사용 가능 (계산식 적용)

### 6️⃣ 윈도우 함수 (Rolling, Expanding)

```
df["rolling_avg"] = df["sales"].rolling(window=3).mean()
df["expanding_sum"] = df["sales"].expanding().sum()
```

- **rolling()**: 고정된 창에서 이동 평균, 합계 등
- **expanding()**: 시작부터 현재까지 누적

### 7️⃣ 시계열 데이터 처리

```
df["date"] = pd.to_datetime(df["date"])
df.set_index("date", inplace=True)
df.resample("M").sum()     # 월별 합계
df["2023-01":"2023-03"]    # 슬라이스
```

- `resample()`: 시계열 리샘플링 (주기 변환)
- 주기 문자열 예: `"D"`(일), `"W"`(주), `"M"`(월), `"Y"`(연)

### 8️⃣ 결측값 고급 처리

```
df.interpolate(method="linear")  # 선형 보간
df.fillna(method="ffill")        # 앞 값으로 채우기
df.fillna(method="bfill")        # 뒷 값으로 채우기
```

### 9️⃣ 범주형 변수 처리 (`Categorical`)

```
df["grade"] = pd.Categorical(df["grade"], categories=["C", "B", "A"], ordered=True)
```

- 메모리 절약
- 정렬/비교 등에서 성능 향상
- `cut()`, `qcut()`으로 연속값을 범주화

```
pd.cut(df["age"], bins=[0, 18, 35, 60], labels=["청소년", "청년", "중장년"])
```

### 🔟 이상치 탐지 및 정제

```
q1 = df["value"].quantile(0.25)
q3 = df["value"].quantile(0.75)
iqr = q3 - q1
outliers = df[(df["value"] < q1 - 1.5 * iqr) | (df["value"] > q3 + 1.5 * iqr)]
```

### 🔁 반복 가능한 데이터 변환 체인 (method chaining)

```
df_cleaned = (
    df.dropna()
      .query("score >= 70")
      .assign(log_score=lambda x: np.log1p(x["score"]))
      .sort_values("log_score", ascending=False)
)
```

### 📌 요약 테이블

| 작업             | 메서드                                |
| ---------------- | ------------------------------------- |
| 그룹 집계        | `groupby()`, `agg()`                  |
| 사용자 함수 적용 | `apply()`, `map()`                    |
| 피벗/변형        | `pivot_table()`, `melt()`             |
| 다중 인덱스      | `set_index()`, `reset_index()`        |
| 조건식           | `query()`                             |
| 이동/누적 계산   | `rolling()`, `expanding()`            |
| 시계열 처리      | `to_datetime()`, `resample()`         |
| 결측 보간        | `interpolate()`, `fillna(method=...)` |
| 범주형 처리      | `Categorical`, `cut()`, `qcut()`      |

이러한 고급 기능들을 조합하면 **데이터 전처리, 통계 분석, 피처 엔지니어링**까지 대부분을 `pandas`로 해결할 수 있다.