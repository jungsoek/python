# 14. 인공지능 및 머신러닝 입문

## `scikit-learn` 사용법

### 1. 📦 scikit-learn이란?

`scikit-learn`은 **Python 기반의 머신러닝 라이브러리**로, 다음과 같은 작업을 빠르게 구현할 수 있게 해줘:

- 분류(Classification)
- 회귀(Regression)
- 군집(Clustering)
- 차원 축소(Dimensionality Reduction)
- 모델 선택(Model Selection)
- 데이터 전처리(Preprocessing)

> NumPy, SciPy, matplotlib 위에 구축되어 있어. 대규모 딥러닝이 아니라 **기초 통계/ML 입문에 최적화된 라이브러리**야.

### 2. 📦 설치 방법

```
pip install scikit-learn
```

추가적으로 다음도 설치 추천:

```
pip install numpy pandas matplotlib seaborn
```

### 3. 🧭 전체 사용 흐름 (머신러닝 파이프라인)

```
[데이터 수집] → [전처리] → [모델 선택] → [학습 (fit)] → [예측 (predict)] → [평가 (score)]
```

`scikit-learn`은 이 전체 흐름을 일관된 API로 지원함.

### 4. 📌 주요 기능별 핵심 사용법

#### ✅ 4.1 데이터 불러오기 및 전처리

```
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 데이터 로딩
iris = load_iris()
X, y = iris.data, iris.target

# 훈련/테스트 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 정규화 (평균=0, 분산=1)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```

#### ✅ 4.2 모델 선택 및 학습

```
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
```

#### ✅ 4.3 예측 및 평가

```
from sklearn.metrics import accuracy_score, classification_report

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
```

### 5. 📊 주요 분류 모델들

| 모델                   | 클래스 이름                   |
| ---------------------- | ----------------------------- |
| 로지스틱 회귀          | `LogisticRegression`          |
| 서포트 벡터 머신 (SVM) | `SVC`, `LinearSVC`            |
| 결정 트리              | `DecisionTreeClassifier`      |
| 랜덤 포레스트          | `RandomForestClassifier`      |
| K-최근접 이웃          | `KNeighborsClassifier`        |
| 나이브 베이즈          | `GaussianNB`, `MultinomialNB` |
| 신경망                 | `MLPClassifier`               |

### 6. 📈 회귀 모델들

| 모델               | 클래스 이름             |
| ------------------ | ----------------------- |
| 선형 회귀          | `LinearRegression`      |
| 릿지 회귀          | `Ridge`                 |
| 라쏘 회귀          | `Lasso`                 |
| 결정 트리 회귀     | `DecisionTreeRegressor` |
| 랜덤 포레스트 회귀 | `RandomForestRegressor` |
| 서포트 벡터 회귀   | `SVR`                   |

### 7. 🔍 교차 검증 및 모델 평가

```
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5)
print("Cross-validation 평균 정확도:", scores.mean())
```

### 8. 🔄 하이퍼파라미터 튜닝

```
from sklearn.model_selection import GridSearchCV

params = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 10, 20]
}
grid = GridSearchCV(RandomForestClassifier(), params, cv=5)
grid.fit(X_train, y_train)

print("최적 파라미터:", grid.best_params_)
```

### 9. 📉 차원 축소 (PCA 예시)

```
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X)

plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y)
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("PCA Visualization")
plt.show()
```

### 🔚 10. 요약

| 단계   | 함수 / 클래스                             | 설명                  |
| ------ | ----------------------------------------- | --------------------- |
| 데이터 | `datasets.load_*`, `train_test_split`     | 데이터 불러오기, 분할 |
| 전처리 | `StandardScaler`, `MinMaxScaler`          | 정규화, 스케일링      |
| 모델   | `RandomForestClassifier`, `SVC`, ...      | 모델 선택             |
| 학습   | `model.fit()`                             | 학습                  |
| 예측   | `model.predict()`                         | 예측                  |
| 평가   | `accuracy_score`, `classification_report` | 모델 성능 평가        |
| 검증   | `cross_val_score`, `GridSearchCV`         | 모델 선택과 튜닝      |

## 데이터 전처리 및 학습

### 1. 🧱 전처리가 중요한 이유

머신러닝 모델은 **쓰레기 데이터를 넣으면 쓰레기 결과가 나온다**는 "GIGO(Garbage In, Garbage Out)" 원칙에 철저히 따름.

데이터 전처리는 다음과 같은 문제를 해결해:

- 누락된 값 (Missing Value)
- 범주형 처리 (Categorical Encoding)
- 스케일링 및 정규화
- 이상치 처리
- 클래스 불균형
- 데이터 분할 (Train/Test)

### 2. 🧼 주요 전처리 기법 정리

#### ✅ 2.1 결측값 처리

```
import numpy as np
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')  # or median, most_frequent
X_filled = imputer.fit_transform(X)
```

#### ✅ 2.2 범주형 데이터 인코딩

```
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse=False)
X_encoded = encoder.fit_transform(X_categorical)
```

또는 `pandas.get_dummies()`를 사용:

```
import pandas as pd
df = pd.get_dummies(df, columns=['sex', 'region'])
```

#### ✅ 2.3 특성 스케일링 (Normalization / Standardization)

```
from sklearn.preprocessing import StandardScaler, MinMaxScaler

scaler = StandardScaler()  # 평균=0, 분산=1
X_scaled = scaler.fit_transform(X)

scaler = MinMaxScaler()    # 0~1 사이로 변환
X_scaled = scaler.fit_transform(X)
```

#### ✅ 2.4 이상치 제거

```
from scipy import stats
z_scores = np.abs(stats.zscore(X))
X_clean = X[(z_scores < 3).all(axis=1)]  # Z-score 기준
```

또는 IQR 방식:

```
Q1 = np.percentile(X, 25, axis=0)
Q3 = np.percentile(X, 75, axis=0)
IQR = Q3 - Q1
mask = (X >= (Q1 - 1.5 * IQR)) & (X <= (Q3 + 1.5 * IQR))
X_clean = X[mask.all(axis=1)]
```

#### ✅ 2.5 클래스 불균형 처리 (오버샘플링/언더샘플링)

```
from imblearn.over_sampling import SMOTE
smote = SMOTE()
X_resampled, y_resampled = smote.fit_resample(X, y)
```

※ `imblearn`은 별도 설치 필요:

```
pip install imbalanced-learn
```

### 3. 🧪 데이터 분할

```
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
```

> `stratify=y`를 꼭 써줘야 클래스 분포를 유지한 상태로 분할돼.

### 4. 🔁 학습 (fit) 과정

#### 기본 흐름

```
model = SomeClassifier()
model.fit(X_train, y_train)
```

#### 예: 랜덤 포레스트 학습

```
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=100, max_depth=5)
model.fit(X_train, y_train)
```

### 5. 🔄 전처리와 학습의 연결 — `Pipeline`

모든 전처리와 모델 학습 과정을 하나로 묶기!

```
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', LogisticRegression())
])

pipe.fit(X_train, y_train)
```

> 이제 `pipe.predict()`만 쓰면 모든 전처리를 자동 수행한 뒤 예측까지 해줌.

### 6. 📉 훈련 정확도 vs 테스트 정확도

| 상황           | 의미                    | 해결책                         |
| -------------- | ----------------------- | ------------------------------ |
| 훈련↑, 테스트↓ | 과적합 (overfitting)    | 모델 단순화, 정규화, Dropout   |
| 훈련↓, 테스트↓ | 과소적합 (underfitting) | 모델 복잡도 증가, feature 추가 |
| 훈련≈테스트    | 일반화 양호             | Best 상태                      |

### 7. 📋 전처리 자동화 예시 코드 전체

```
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# 1. 데이터
data = load_breast_cancer()
X, y = data.data, data.target

# 2. 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)

# 3. 파이프라인 구성
pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', RandomForestClassifier(n_estimators=100))
])

# 4. 학습
pipe.fit(X_train, y_train)

# 5. 평가
y_pred = pipe.predict(X_test)
print("정확도:", accuracy_score(y_test, y_pred))
```

### ✅ 마무리 요약

| 항목          | 설명                             |
| ------------- | -------------------------------- |
| 결측값 처리   | 평균/중앙값 등으로 채움          |
| 범주형 인코딩 | OneHotEncoder 또는 get_dummies   |
| 스케일링      | StandardScaler / MinMaxScaler    |
| 이상치 제거   | Z-score, IQR 방법                |
| 클래스 불균형 | SMOTE 등 오버샘플링              |
| 데이터 분할   | `train_test_split` 사용          |
| 파이프라인    | 전처리 + 모델 학습을 하나로 통합 |
| 모델 학습     | `fit()` 메서드 사용              |

## 기본 모델 적용 및 평가

### 🧭 전체 프로세스 요약

```
[전처리] → [모델 선택] → [학습] → [예측] → [평가]
```

모델을 훈련하고 결과를 분석하는 게 핵심인데, 어떤 문제를 다루는지에 따라 평가 방식이 달라져.

- **분류 문제 (Classification)**: 이진/다중 클래스 분류
- **회귀 문제 (Regression)**: 연속적인 수치 예측

### ✅ 1. 분류 문제: 예측 및 평가

#### 📌 예측

```
y_pred = model.predict(X_test)
```

확률로 예측하고 싶다면:

```
y_prob = model.predict_proba(X_test)  # 각 클래스에 대한 확률
```

#### 📌 평가 지표

**🎯 1) 정확도 (Accuracy)**

```
from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred)
```

> 전체 중 맞춘 비율. **클래스 불균형이 심하면 왜곡될 수 있음**

**🟨 2) 정밀도 / 재현율 / F1 점수**

```
from sklearn.metrics import precision_score, recall_score, f1_score

precision_score(y_test, y_pred)
recall_score(y_test, y_pred)
f1_score(y_test, y_pred)
```

| 지표               | 의미                               |
| ------------------ | ---------------------------------- |
| 정밀도 (Precision) | 예측이 참인 것 중 실제로 참인 비율 |
| 재현율 (Recall)    | 실제 참인 것 중 예측도 참인 비율   |
| F1-score           | 정밀도와 재현율의 조화 평균        |

> 예: 스팸 필터, 암 진단에서 재현율이 중요
>  반대로 신용카드 사기 탐지에서는 정밀도가 중요

**📊 3) confusion matrix (혼동 행렬)**

```
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_pred))
```

|           | 실제 양성 | 실제 음성 |
| --------- | --------- | --------- |
| 예측 양성 | TP        | FP        |
| 예측 음성 | FN        | TN        |

**📈 4) ROC-AUC (이진 분류만)**

```
from sklearn.metrics import roc_auc_score
roc_auc_score(y_test, y_prob[:,1])
```

> 1에 가까울수록 좋음. 0.5는 랜덤과 같음.

**📋 5) 전체 리포트**

```
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))
```

#### 🧪 예시 코드 (RandomForestClassifier)

```
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

data = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, stratify=data.target, random_state=42)

model = RandomForestClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(classification_report(y_test, y_pred))
```

### ✅ 2. 회귀 문제: 예측 및 평가

#### 📌 예측

```
y_pred = model.predict(X_test)
```

#### 📌 평가 지표

| 지표                      | 설명                     | 함수                  |
| ------------------------- | ------------------------ | --------------------- |
| MSE (Mean Squared Error)  | 제곱 오차 평균           | `mean_squared_error`  |
| RMSE (Root MSE)           | √MSE, 해석 쉬움          | `np.sqrt(mse)`        |
| MAE (Mean Absolute Error) | 절댓값 오차 평균         | `mean_absolute_error` |
| R² (결정 계수)            | 예측력의 비율 (1이 최고) | `r2_score`            |

```
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
```

#### 🧪 예시 코드 (LinearRegression)

```
from sklearn.linear_model import LinearRegression
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

data = fetch_california_housing()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print("R²:", r2_score(y_test, y_pred))
```

### ✅ 3. 교차 검증으로 모델 평가 안정화

```
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')  # 분류
scores = cross_val_score(model, X, y, cv=5, scoring='r2')         # 회귀
print("평균 성능:", scores.mean())
```

### ✅ 4. 평가 지표 선택 요령

| 문제 유형 | 상황 예시 | 추천 지표              |
| --------- | --------- | ---------------------- |
| 이진 분류 | 암 진단   | `Recall`, `ROC-AUC`    |
| 이진 분류 | 금융 사기 | `Precision`, `F1`      |
| 다중 분류 | 뉴스 분류 | `Accuracy`, `macro F1` |
| 회귀      | 주가 예측 | `RMSE`, `MAE`, `R²`    |

### 🔁 전체 요약

| 단계                      | 설명                     |
| ------------------------- | ------------------------ |
| `predict()`               | 예측값 생성              |
| `accuracy_score()`        | 정확도 평가              |
| `confusion_matrix()`      | 혼동 행렬 분석           |
| `classification_report()` | 주요 분류 지표 일괄 출력 |
| `mean_squared_error()`    | 회귀 오차                |
| `cross_val_score()`       | 교차 검증 정확도 평가    |

## `TensorFlow`, `PyTorch` 프레임워크 개요

| 항목                  | TensorFlow                               | PyTorch                                   |
| --------------------- | ---------------------------------------- | ----------------------------------------- |
| 💻 개발사              | Google                                   | Meta (Facebook)                           |
| 🧠 주요 목적           | 상용 배포, 모바일, 다중 플랫폼 지원      | 연구/개발 유연성, 실험 및 프로토타이핑    |
| 🧮 계산 그래프         | 정적 (Static Graph)                      | 동적 (Dynamic Graph, define-by-run)       |
| 🛠 대표 API            | `tf.keras` (고수준 API 중심)             | `torch.nn`, `torch.optim` (유연한 저수준) |
| 🧩 사용 난이도         | 초심자에게 쉬움 (`fit`, `evaluate`)      | Pythonic하지만 수동 루프 필요             |
| 🔍 디버깅              | 어렵고 비직관적 (Graph 기반)             | Python처럼 직접 디버깅 가능               |
| ⚙️ 커스터마이징 자유도 | 중간 (Keras에선 제한)                    | 매우 높음 (복잡한 분기문, 재귀 모델 등)   |
| 📦 배포 및 서빙        | 매우 강력 (`TF Serving`, `TFLite`, `JS`) | TorchScript, ONNX 등으로 제한적 지원      |
| 🚀 GPU/TPU 지원        | GPU + TPU (공식 지원)                    | GPU (TPU는 간접 지원)                     |
| 📊 시각화 도구         | TensorBoard                              | TensorBoard, wandb, Visdom                |
| 🤖 전이 학습           | `tf.keras.applications`                  | `torchvision.models`, HuggingFace 등      |

### ✨ 공통 기능

- 텐서(Tensor) 기반 고차원 연산
- 자동 미분 (Autograd)
- 신경망 구성 (Sequential, Custom Module)
- GPU 가속 지원
- 학습 루프 구성 (`fit()` 또는 커스텀 루프)
- 전이 학습, 사전 훈련 모델, 서빙 API 존재

### 🔍 예제 비교

#### ✅ TensorFlow (Keras 기반)

```
import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)
])
model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, epochs=10)
```

#### ✅ PyTorch (직접 루프)

```
import torch
import torch.nn as nn
import torch.optim as optim

class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(10, 1)

    def forward(self, x):
        return self.fc(x)

model = Net()
optimizer = optim.Adam(model.parameters())
criterion = nn.MSELoss()

for epoch in range(10):
    optimizer.zero_grad()
    output = model(X_train)
    loss = criterion(output, y_train)
    loss.backward()
    optimizer.step()
```

### ✅ 언제 무엇을 쓸까?

| 목적              | 추천 프레임워크         |
| ----------------- | ----------------------- |
| 입문 학습         | TensorFlow (`tf.keras`) |
| 연구/논문 실험    | PyTorch                 |
| 산업 배포         | TensorFlow              |
| 복잡한 구조 모델  | PyTorch                 |
| Google Cloud 연동 | TensorFlow              |
| 빠른 프로토타입   | PyTorch                 |

### 🧠 결론

- **TensorFlow**: 기업 환경, 배포, 높은 생산성을 원한다면
- **PyTorch**: 자유도, 디버깅 편의성, 실험 중심 개발을 원한다면

### 다음 주제

- `fit()` 없이 학습 루프 직접 구현하기
- CNN / RNN 구조 설계
- GPU 학습 방법 (`.cuda()` / `tf.device`)
- Hugging Face 사전학습 모델 연동